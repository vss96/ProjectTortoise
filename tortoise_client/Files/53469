{"author_flair_text":null,"author":"cgibbard","parent_id":"t3_vebs","id":"cvf91","edited":false,"gilded":0,"retrieved_on":1473808969,"distinguished":null,"body":"I disagree with this article in a bunch of small ways, and it really looks to me, from looking at the abstract of the talk referred to, that various points might have been misunderstood.\r\n\r\nFirstly, it is possible to get a wide variety of guarantees of compositionality in transactional memory systems. [Haskell's STM library](http://research.microsoft.com/~simonpj/papers/stm/index.htm) does quite a good job of providing a fair degree of compositionality guarantees, for instance. It does not support nested transactions, but if nested transactions make compositionality hard to obtain, perhaps they are the wrong idea.\r\n\r\nCertainly, you can't completely eliminate problems with deadlock, there are still ways for a program to request impossible uses of resources, but these systems do eliminate many many sources of these problems.\r\n\r\nThere's a parallel situation with type systems. Good type systems like those in Haskell, ML, Scala, etc. don't magically catch all your bugs, but they do help eliminate wide classes of bugs which may arise before they become real problems, freeing more time for programmers to worry about the more subtle bugs.\r\n\r\nIndeed, we really need many idioms and ways of looking at parallelism and concurrency. Locks are not a terribly useful substrate on which to build libraries, and anyone who has tried to use that model understands why this is difficult. I agree with the speakers that automatic translation of lock-based code is very likely to be problematic.\r\n\r\nHowever, the ability to mark code such that it runs as-if-atomically, (perhaps together with some variety of means of combining transactions) is exactly the sort of abstraction which will allow development to move forward in terms of higher-level libraries, while compiler authors and hardware manufacturers work out better and better ways to run these \"atomic\" blocks in parallel to gain performance without damaging the semantic guarantees which have been set up.\r\n\r\nThere are various potential design flaws which we have to be careful not to put into our foundations. Transactions should never have intermittent side effects visible before their completion, nor should the effects of any other concurrently running processes be visible from within them. They should behave as if they ran atomically -- when they fail, it should be as if nothing had happened at all. That's the whole point of them being transactions. This means that they cannot have side effects which cannot be rolled back in the case of failure (notably I/O). Of course, it's possible to design systems where transactions queue and/or trigger I/O to occur after they've completed.\r\n\r\nSo I think the tone of the article is a little more negative than is probably appropriate. Yes, there are migration issues if you want to translate lock based code mechanically to use transactions. Yes, there are design choices which must be made carefully. Overall, however, transactions form a much nicer semantic substrate than locks, and will allow a great deal of progress to occur in terms of higher level libraries, as well as lower level performance optimisations.","controversiality":0,"stickied":false,"link_id":"t3_vebs","subreddit_id":"t5_2fwo","subreddit":"programming","created_utc":1166568535,"author_flair_css_class":null,"score":4,"ups":4,"timestamp_epoch":1566236773,"message_id":"39573-fae561b7-6547-4add-8ac8-2c20ddb63b59-1566236773"}