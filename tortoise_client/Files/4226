{"body":"&gt; I'm a software developer, I love making peoples life easier through software. For people like me, programming languages are tools, means to an end.\r\n\r\nI have similar goals and principles, but wildly different interpretations.  My parents use the computer *only* for e-mail, websurfing, and word processing.  I suspect they're like most older folks in that regard.  I perpetually have to clean up after their mess - not because they did anything wrong, but because the the software makes it impossible to do anything right.  Crashes, misconfigurations, spyware, viruses, freezes, deadlocks, lost data - just about everything that can go wrong with computers does go wrong.\r\n\r\nThen I look at the code I write.  As a quick &amp; dirty estimate, 70% of my bugs are due to mismanaged mutable state - the system does not currently hold the data I expect.  Another 20% are type errors of some sort.  Only about 10% of defects are logical errors, cases where I didn't actually understand the problem enough.  (This is for JavaSE programming - when I factor in the Unified Expression Language that Sun saw fit to introduce with JavaEE, 50% of my bugs are mistyped tag/attribute/variable names.)\r\n\r\nThen I look at Haskell, which has completely eliminated state from the programming process.  It has also completely eliminated type errors.  That is 90% of bugs, **gone** - they simply can't happen.  It's not *hiding* bugs, it's not *testing* for bugs - the types of errors that you make with mainstream programming languages simply cannot occur.  In my actual experience programming with Haskell, programs are usually correct once they pass the typechecker.  If they're not, it's typically either some cosmetic issue that can be fixed in literally 30 seconds, or I didn't understand the language somewhere.\r\n\r\nI'm willing to put up with a lot of pain to never pick up a debugger again.\r\n\r\nIf there was no C++, there would be no buffer overflows.  It sounds like simplistic hyperbole, but it's not: the memory model of most other languages simply doesn't allow it.  If there were no null pointers, there would be no NullPointerExceptions.  If everyone used languages that make you declare variables before you use them, you wouldn't have mistyping errors that silently propagate bad values through the program.\r\n\r\nLanguages matter.  There are *huge* classes of problems that can be eliminated - completely - with some of these newfangled languages.  The problem is, they usually introduce new classes of problems, and they require that you solve the old ones again.  That's a big barrier to entry.  But I think that things are fundamentally broken enough in the software industry that it'll pay off, over the next 10-20 years.","controversiality":0,"link_id":"t3_t1cf","stickied":false,"subreddit_id":"t5_2fwo","subreddit":"programming","author_flair_css_class":null,"created_utc":1164955908,"score":7,"ups":7,"author_flair_text":null,"author":"nostrademons","edited":false,"id":"ct764","parent_id":"t1_ct703","gilded":0,"retrieved_on":1473807465,"distinguished":null,"timestamp_epoch":1566236758,"message_id":"742-bc21660f-3e73-48e0-aae0-9f2300df0430-1566236758"}