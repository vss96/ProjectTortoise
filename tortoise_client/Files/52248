{"author":"ricercar","author_flair_text":null,"parent_id":"t1_cwa39","id":"cwal4","edited":false,"gilded":0,"retrieved_on":1473809568,"distinguished":null,"controversiality":0,"body":"Your examples demonstrate my point almost precisely.  You are influenced by imperative algorithmic approaches, but none of them require it (perhaps the GUI, but that would be in the IO monad anyhow, which renders it referentially transparent to the rest of the program).\r\n\r\nThere is nothing inherently imperative about a forward inference engine.  From your description, I would characterize that as a type `s` representing state, and a transition function `f` of `a -&gt; s -&gt; s` for some type of input `a`.  \r\n\r\nPerhaps I am being influenced by my own current project, which is similar in some ways.  I have approached it as an iterative heuristic-based search with a search-state transition function which is called repeatedly until a goal condition is satisfied.  I wrap up the notions of \"initial state\", \"state transition\", \"goal condition\", and \"failure condition\" in a type-class such that multiple implementations can (and do) co-exist.\r\n\r\nThe search itself is performed by attempting to enforce certain constraints in a constraint-network according to the currently expanded node.  The functions of the constraint-network are referentially transparent which means that backtracking is a no-brainer.\r\n\r\nThe best part is that parallelizing the search was simply a matter of substituting `parMap` for `map` in one place, and writing a very simple `NFData` instances for my solution data type; just a couple extra lines which force the computation to complete in its own thread.  Now I can just specify a flag to the runtime system and get a 20-30% reduction in real time (depending on the input) on multiple-core systems.\r\n\r\nSpeed is very important, and I've ensured the minimal amount of computation necessary is performed by use of lazy evaluation to memoize results.  In addition, it prevents divergence in algorithms which would otherwise have to be rewritten to handle cycles (in that particular graph), explicitly.  Deforestation and fusion optimizations performed by the compiler are key to allowing the programmer to enjoy natural use of functions, which eventually boil down to tight code.\r\n\r\nAll these advantages would be destroyed if I were to insert some kind of mutation; even explicit sequencing would hurt in some cases.  The initial impulse to mutate the node links was \"naive\" on my part, so to speak, because I do want to preserve the nice properties of the code.\r\n\r\nI'm very happy with Haskell so far, even if some of the tools and libraries are a bit primitive (I'm coming from Common Lisp) relatively.  I've always enjoyed the functional style, but it simply does not work out as nicely in more \"traditional\" strictly evaluated language; I've worked in Standard ML a good deal prior, and gained a bit of distaste for the practicalities of that (though it is a clean and fairly elegant language).\r\n","stickied":false,"link_id":"t3_w79v","subreddit_id":"t5_2fwo","subreddit":"programming","created_utc":1167342445,"author_flair_css_class":null,"score":4,"ups":4,"timestamp_epoch":1566236779,"message_id":"55613-b5bd88a2-e46c-43ab-808d-10446d1dac51-1566236779"}