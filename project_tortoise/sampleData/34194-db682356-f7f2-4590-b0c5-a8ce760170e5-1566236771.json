{"score":1,"ups":1,"created_utc":1166380969,"author_flair_css_class":null,"subreddit":"programming","subreddit_id":"t5_2fwo","stickied":false,"link_id":"t3_uz8g","controversiality":0,"body":"This is what I mean: Let's say you are using a 64-bit key. A theoretical cryptographer will tell you that he'll need, on average, 2^32 attempts to decrypt your message.\r\n\r\nAssume he can run one attempt per second. Then, It'll take him 2^32 seconds to decrypt your file.\r\n\r\nNow, assume that it actually takes 3 seconds to check if a given bunch of 1s and 0s is a valid file. You need to find unicity distances for hundreds of languages, check headers for hundreds of popular filetypes, etc.\r\n\r\nIn this case, each attempt actually takes 4 seconds. So, a practical cryptographer will give you an estimate of 4*2^32=2^34 seconds to decrypt your file.\r\n\r\nFrom the theoretical cryptographer's point of view, the extra time needed to decide if each decryption attempt was successful is equivalent to increasing the key length from 64 to 68 bits.","distinguished":null,"retrieved_on":1473808768,"gilded":0,"parent_id":"t1_cv3ip","id":"cv4no","edited":false,"author_flair_text":null,"author":"buo","timestamp_epoch":1566236771,"message_id":"34194-db682356-f7f2-4590-b0c5-a8ce760170e5-1566236771"}