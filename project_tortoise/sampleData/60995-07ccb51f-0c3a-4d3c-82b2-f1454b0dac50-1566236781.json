{"subreddit_id":"t5_6","link_id":"t3_wkuu","stickied":false,"controversiality":0,"body":"Define \"haven't seen before\": Did you click it? Did you pass over it in a list of other submissions on a page?\r\n\r\nIf it's the former, that's not so bad - reddit already tracks all the links you click on when you're signed in with the 'return rwt(..)' Javascript rewrite of onmousedown. This is to help track story popularity and it also (just a guess here) factors into the \"recommended\" links section.\r\n\r\nIf it's the latter ... you're talking about some serious data bloat there. God knows how many pages of links I skip over on a daily basis looking through the \"new\" submissions page. At least an up/down vote or clicking to view the story takes effort.\r\n\r\nRegardless, both methods create a new problem:\r\n\r\nCurrently when you view a section of reddit, a story shows up on the page a.) because the formula for that page suggested it and b.) you didn't down-vote the story. The formula used in a.), while possibly complex, can also have its results cached for use by every redditor (with the exception of the \"recommended\" and \"saved\" sections - and even \"saved\" can be cached/pre-calculated on a per-user basis). The formula used in b.) is a simple 'set contains' check - likely each story tracks at least two collections of data: 'set of user IDs that voted this story up', 'set of user IDs that voted this story down'. While the time required for this check does increase with the popularity of the story (the #1 story of all time currently has 2600+ ups and 900+ downs), the *average* story on any page tops out at a list of ~100-200 IDs and is often much less than 100 - especially on the \"new\" page. Thus you could say there's a 'reasonable'/predictable amount of work done per-story in generating any particular page to show you.\r\n\r\nThe keyword filter check (we'll call that formula c.) you propose is just one more pre-generation filter that will likely be a small but constant amount of work (under 20 keywords for the average user, let's say - and many people probably wouldn't know about/use it).\r\n\r\nFormula d.) \"what I haven't seen\", though ... I don't know how many users reddit has total but I don't think reddit (currently) records every story you've clicked on. I think they record the clicking and add that into the acceleration/popularity data of the story, but to track every user means an increasing amount of data that grows a.) with time (as you read stories you missed), b.) the number of users, c.) the number of stories - and it never goes away.\r\n\r\nIf they did track it, formula d.) would be performing another 'set contains' check - only now you're comparing against a set that's easily 10+ times the size of the set of people who bothered to vote (you have my sympathy if you tried to view \"top\" of \"all time\" with \"only what I haven't seen before\" turned on).\r\n\r\nSummary:\r\n\r\nWithout a major change in hardware, to do all of the features you've asked for would very likely diminish the 'snappy' feel reddit currently has for you.","score":3,"ups":3,"author_flair_css_class":null,"created_utc":1167608193,"subreddit":"reddit.com","id":"cwl2c","edited":false,"parent_id":"t1_cwkve","author":"pudquick","author_flair_text":null,"distinguished":null,"retrieved_on":1473809764,"gilded":0,"timestamp_epoch":1566236781,"message_id":"60995-07ccb51f-0c3a-4d3c-82b2-f1454b0dac50-1566236781"}