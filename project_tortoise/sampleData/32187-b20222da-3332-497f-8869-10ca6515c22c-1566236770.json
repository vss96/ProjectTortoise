{"retrieved_on":1473808686,"distinguished":null,"gilded":0,"parent_id":"t1_cuzqt","edited":false,"id":"cv0a5","author_flair_text":null,"author":"pjdelport","created_utc":1166257599,"author_flair_css_class":null,"score":5,"ups":5,"subreddit":"programming","stickied":false,"link_id":"t3_uz8g","subreddit_id":"t5_2fwo","body":"&gt; The problem comes when we get into compressed formats (ZIP, but also MP3, JPEG, etc.), which have qualities that make them similar to still-encrypted files in terms of brute-force analysis length.\r\n\r\nActually, most compression algorithms make it much easier to spot the plaintext (even if you assume the adversary is skilled enough to remove obvious headers and so on):  just try to decompress the trial decryption, and discard failures.  This works because most algorithms' decompression side treat only a subset of possible bitstrings as valid input;  they cannot decompress random data.\r\n\r\n(There are refined versions of most compression algorithms available that fix this problem by becoming fully bijective (that is, mapping each decompressed bitstring to exactly one compressed bitstring and vica versa), but these are unfortunately rare in practice.)","controversiality":0,"timestamp_epoch":1566236770,"message_id":"32187-b20222da-3332-497f-8869-10ca6515c22c-1566236770"}