{"gilded":0,"retrieved_on":1473808039,"distinguished":null,"author_flair_text":null,"author":"cecilkorik","parent_id":"t1_cu0ga","edited":false,"id":"cu1uv","subreddit":"reddit.com","created_utc":1165534932,"author_flair_css_class":null,"score":5,"ups":5,"body":"It absolutely is different. Not compiling due to a type error means you mistyped something in the code. There is no question this is an error. It cannot work. Ever.\r\n\r\nDivide by zero, on the other hand, is a runtime error. It may happen as the result of the execution of some code, or it *may not*. That's the critical difference, though it is certainly not the only one.\r\n\r\nMy only problem with exceptions being raised by divide by zero errors, is that it's completely inconsistent, in C at least. I can access an uninitialized variable and get garbage data without having any sort of error or exception. I can do any number of seemingly innocuous but extremely dangerous things without so much as a warning. Why is it so critical then, that a mere divide by zero gives me an application crashing exception rather than just more garbage data or undefined results like everything else in C? Why is divide by zero so sacred?","controversiality":0,"stickied":false,"link_id":"t3_tzna","subreddit_id":"t5_6","timestamp_epoch":1566236762,"message_id":"14886-3b59d63e-3073-4efb-a63c-96017a564db6-1566236762"}