{"author":"notfancy","author_flair_text":null,"id":"cvfvs","edited":false,"parent_id":"t1_cvfqf","gilded":0,"distinguished":null,"retrieved_on":1473808981,"controversiality":0,"body":"&gt; The answer to this question should follow from Chaitin's work on \"elegant programs\" via a Curry-Howard-style correspondence\r\n\r\nThis is a truly elegant answer. Well done!\r\n\r\n&gt; if a proof is very long, can we really believe it?\r\n\r\nIt seems to me that he's using 'to believe' more in an epistemical sense (i.e., related to the plausibility, or parsimony of resources used, in a sort of truthiness metric) than in an absolute axiological (i.e., relating to the absolute truthiness of the theorem) sense. I'd advance the opinion that epistemic confidence is inversely proportional to the Kolmogorov complexity of the proof. In a sense, the more fixed resources (axioms, lemmas, etc.) you have to invoke as assumptions in order to demonstrate your result, the more \"credibility energy\" you have to expend to consume (understand, believe) the theorem.\r\n\r\n&gt; The greater uncertainty here is the platform, of course\r\n\r\nThe encoding is a notorious source of errors, too, in the sense that you might encode a \"correct\" lemma (i.e., a well-typed program) that is wholly \"irrelevant\" to the theorem you're trying to prove. That's why \"programming in logic\" seems to be very much harder than plain old (functional) programming.","subreddit_id":"t5_6","link_id":"t3_veo0","stickied":false,"subreddit":"reddit.com","score":3,"ups":3,"author_flair_css_class":null,"created_utc":1166579079,"timestamp_epoch":1566236773,"message_id":"39943-795f57ae-7f87-45cf-ab0a-dd57e298a040-1566236773"}